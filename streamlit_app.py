import streamlit as st
import pandas as pd
import numpy as np
import pickle
import runpy, os, tempfile
from io import StringIO, BytesIO

st.set_page_config(page_title='HiLabs Risk Predictor', layout='wide')

st.title('HiLabs - Batch Risk Score Predictor')
st.write('Upload the four CSV files (care.csv, patient.csv, diagnosis.csv, risk.csv). The app will preprocess them exactly like the notebook and predict risk for all patients using model_up.pkl.')

st.sidebar.header('Upload CSV files')
patient_file = st.sidebar.file_uploader('Upload patient.csv', type=['csv'])
diagnosis_file = st.sidebar.file_uploader('Upload diagnosis.csv', type=['csv'])
care_file = st.sidebar.file_uploader('Upload care.csv', type=['csv'])
risk_file = st.sidebar.file_uploader('Upload risk.csv', type=['csv'])

if st.sidebar.button('Run prediction'):
    if not (patient_file and diagnosis_file and care_file and risk_file):
        st.error('Please upload all four files.')
    else:
        with st.spinner('Saving uploaded files...'):
            # save uploaded files to working directory with exact names expected by preprocessing script
            open('patient.csv','wb').write(patient_file.getvalue())
            open('diagnosis.csv','wb').write(diagnosis_file.getvalue())
            open('care.csv','wb').write(care_file.getvalue())
            open('risk.csv','wb').write(risk_file.getvalue())

        st.info('Files saved. Running preprocessing pipeline...')

        # write cleaned preprocessing script to temp file
        preproc_path = 'cleaned_preprocessing.py'
        with open(preproc_path, 'w') as f:
            f.write("patient = pd.read_csv('patient.csv')\n\n# ------------------ CELL ------------------\n\n\n\n\ndiagnosis = pd.read_csv('diagnosis.csv')\n\n\n# ------------------ CELL ------------------\n\n\n\n\ncare = pd.read_csv('care.csv')\n\n\n# ------------------ CELL ------------------\n\n\n\nrisk = pd.read_csv('risk.csv')\n\n\n# ------------------ CELL ------------------\n\n\n\nvisit = pd.read_csv('visit.csv')\n\n\n\n# ------------------ CELL ------------------\n\ndf = patient.copy()\n\n# ------------------ CELL ------------------\n\ndf['patient_id'].duplicated().sum()\n\n# ------------------ CELL ------------------\n\n# Ensure date columns are datetime objects\ndate_columns = ['visit_start_dt', 'visit_end_dt', 'follow_up_dt']\nfor col in date_columns:\n    if col in visit.columns:\n        visit[col] = pd.to_datetime(visit[col], errors='coerce')\n\n# Find the latest date across all relevant columns\nlatest_date_in_visit = visit[date_columns].max().max()\n\nprint(f\"The latest date in the visit data is: {latest_date_in_visit}\")\n# Convert 'hot_spotter_identified_at' to datetime objects\ndf['hot_spotter_identified_at'] = pd.to_datetime(df['hot_spotter_identified_at'], errors='coerce')\n\n# Calculate the time difference in days since the hotspot was identified\n# Use the latest_date_in_visit found previously as the reference\ndf['time_since_hotspot_identified'] = (latest_date_in_visit - df['hot_spotter_identified_at']).dt.days\n\ndf.drop('hot_spotter_identified_at', axis=1 ,inplace=True )\n\n# ------------------ CELL ------------------\n\n\n\n# ------------------ CELL ------------------\n\n# Combine msrmnt_type and msrmnt_sub_type in the care table\ncare['msrmnt_type_subtype'] = care['msrmnt_type'] + '_' + care['msrmnt_sub_type']\n\n# Group by patient_id and aggregate the combined string, handling potential NaNs\ncare_aggregated = care.groupby('patient_id')['msrmnt_type_subtype'].apply(lambda x: '_'.join(x.dropna().unique())).reset_index()\n\n# Merge the aggregated care data with the df DataFrame\ndf = pd.merge(df, care_aggregated, on='patient_id', how='left')\n\n# Display the updated df DataFrame\n\n# ------------------ CELL ------------------\n\n# Group care by patient_id and aggregate care_gap_ind\ncare_gap_aggregated = care.groupby('patient_id')['care_gap_ind'].apply(lambda x: '_'.join(x.dropna().unique())).reset_index()\n\n# Merge with df\ndf = pd.merge(df, care_gap_aggregated, on='patient_id', how='left')\n\n# Display the updated df DataFrame\n\n# ------------------ CELL ------------------\n\n# Get unique condition names from the diagnosis table\nunique_conditions = diagnosis['condition_name'].unique()\n\n# Create a new DataFrame with patient_id and a column of ones\ndiagnosis_binary = diagnosis[['patient_id', 'condition_name']].copy()\ndiagnosis_binary['has_condition'] = 1\n\n# Pivot the table to get unique conditions as columns\ndiagnosis_pivot = diagnosis_binary.pivot_table(\n    index='patient_id',\n    columns='condition_name',\n    values='has_condition',\n    fill_value=0\n).reset_index()\n\n# Merge the new binary columns with the df DataFrame\ndf = pd.merge(df, diagnosis_pivot, on='patient_id', how='left')\n\n# Fill NaN values (for patients not in diagnosis) with 0\nfor condition in unique_conditions:\n    df[condition] = df[condition].fillna(0)\n\n# ---- NEW CODE: Calculate chronic_ratio ----\ndf['chronic_ratio'] = df[unique_conditions].sum(axis=1) / len(unique_conditions)\n\n# Display updated DataFrame\n\n\n# ------------------ CELL ------------------\n\n# --- Unique diagnosis values (drop NaN early)\nunique_visit_diag = visit['prncpl_diag_nm'].dropna().unique()\n\n# --- Build patient \u00d7 diagnosis multi-hot (presence = 1)\nvisit_binary = (\n    visit[['patient_id', 'prncpl_diag_nm']]\n      .dropna(subset=['prncpl_diag_nm'])\n      .assign(has_diag=1)\n)\n\nvisit_pivot = (\n    visit_binary\n      .pivot_table(\n          index='patient_id',\n          columns='prncpl_diag_nm',\n          values='has_diag',\n          aggfunc='max',        # presence if ever seen\n          fill_value=0\n      )\n      .rename_axis(None, axis=1)\n)\n\n# Optional: add a prefix to avoid collisions\nvisit_pivot = visit_pivot.add_prefix('dx_')\n\n# Make it small: store as uint8 (or bool)\nvisit_pivot = visit_pivot.astype('uint8')\n\n# --- Merge into your main df on patient_id\ndf = df.merge(visit_pivot.reset_index(), on='patient_id', how='left')\n\n# Columns that were absent for some patients will be NaN after merge; fill them:\ndx_cols = [c for c in df.columns if c.startswith('dx_')]\ndf[dx_cols] = df[dx_cols].fillna(0).astype('uint8')\n\n# --- Ratios / totals based on distinct diagnoses present\ndf['visit_diag_ratio'] = df[dx_cols].sum(axis=1) / len(dx_cols)\ndf['total_visit_diagnoses'] = df[dx_cols].sum(axis=1)\n\n# peek\n\n\n# ------------------ CELL ------------------\n\nimport pandas as pd\nimport re\n\n# -----------------------------\n# 1) BINNING RULES\n# -----------------------------\nrules = [\n    ('Respiratory Infection', r'infection|pneumonia|bronchitis|pharyngitis|laryngitis|tracheitis|tonsillitis|sinusitis|nasopharyngitis|flu|influenza|covid'),\n    ('Lower Respiratory', r'pneumonia|bronchitis|bronchiolitis|wheezing|asthma|copd'),\n    ('Upper Respiratory', r'cough|cold|throat|upper respiratory|pharyngitis|laryngitis'),\n    ('ENT', r'otitis|ear|sinus|sinusitis|epistaxis|rhinitis|cerumen|tonsil|throat|pharynx|larynx'),\n    ('Musculoskeletal', r'strain|sprain|fracture|contusion|myalgia|arthritis|back pain|shoulder|wrist|knee|hip|ligament|muscle|joint|tendon|osteo|sciatica'),\n    ('Injury/Wound', r'injury|wound|laceration|open wound|foreign body|bite|burn|abrasion|crush|trauma|contusion|dislocation|fracture|amputation'),\n    ('Skin/Soft Tissue', r'cellulitis|abscess|furuncle|erythematous|dermatitis|rash|swelling|urticaria|cyst|ulcer|bite|laceration|wound|pruritus'),\n    ('GU', r'cystitis|urinary|bladder|hematuria|pyelonephritis|prostatitis|incontinence|urethritis'),\n    ('GI', r'abdominal|gastro|nausea|vomiting|epigastric|colitis|diarrhea|constipation|appendicitis|gastritis|pancreatitis|hepatitis|hernia|peritonitis|cholecystitis|gallbladder|bleeding|hemorrhoids|gerd|reflux|diverticulitis'),\n    ('Neurology/Psych', r'headache|migraine|dizz|giddiness|vertigo|syncope|collapse|seizure|epilepsy|paralysis|stroke|tremor|neuro|disorder|depression|anxiety|mood|insomnia|sleep'),\n    ('Cardiovascular', r'chest pain|palpitations|hypertension|tachy|arrhythmia|heart failure|infarction|angina|embolism|thrombosis|atherosclerosis|hypotension|stemi|nstemi'),\n    ('Obstetric/Gyne', r'pregnancy|labor|childbirth|preterm|vaginitis|menstruation|miscarriage|abortion|perineal|postpartum|uterovaginal|ovarian|endometriosis|fetal|maternal care|gestational'),\n    ('Endocrine/Metabolic', r'diabetes|thyroid|metabolic|nutritional|obesity|hypoglycemia|ketoacidosis|electrolyte|hypokalemia|hyperglycemia'),\n    ('Eye', r'conjunctivitis|hordeolum|chalazion|stye|blepharitis|cataract|glaucoma|corneal|iridocyclitis|retinal'),\n    ('Other Infection', r'viral|bacterial|abscess|sepsis|tuberculosis|mononucleosis|infection'),\n    ('Allergy/Immune', r'allergy|urticaria|anaphylaxis|angioedema|immune|contact dermatitis'),\n    ('Pain', r'pain'),\n    ('Other', r'fever|malaise|fatigue|unspecified|other|abnormal|screening|observation|follow-up'),\n]\n\ndef bin_diagnosis(text):\n    if pd.isnull(text):\n        return 'Other'\n    t = text.lower()\n    for cat, pat in rules:\n        if re.search(pat, t):\n            return cat\n    return 'Other'\n\n# -----------------------------\n# 2) APPLY BINNING\n# -----------------------------\nvisit['diag_bin'] = visit['prncpl_diag_nm'].apply(bin_diagnosis)\n\n# -----------------------------\n# 3) One-hot diag bins + visit types\n# -----------------------------\ndiag_dummies = pd.get_dummies(visit['diag_bin'], prefix='diag', dtype=int)\nvisit_type_dummies = pd.get_dummies(visit['visit_type'], prefix='visit_type', dtype=int)\n\n# -----------------------------\n# 4) readmission mapping\n# -----------------------------\ndef encode_flag(value):\n    if pd.isna(value):\n        return 0  # or -1 if you prefer\n    return int(bool(value))\n\nvisit['readmsn_ind'] = visit['readmsn_ind'].apply(encode_flag)\n\n# -----------------------------\n# 5) Combine + aggregate\n# -----------------------------\ndf_for_agg = pd.concat([visit[['patient_id', 'readmsn_ind']], visit_type_dummies, diag_dummies], axis=1)\n\n# dynamic aggregations\naggregations = {\n    **{c: (c, 'sum') for c in visit_type_dummies.columns},\n    **{c: (c, 'sum') for c in diag_dummies.columns},\n    'visit_count': ('readmsn_ind', 'count'),\n    'total_readmissions': ('readmsn_ind', 'sum')\n}\n\npatient_summary = df_for_agg.groupby('patient_id').agg(**aggregations).reset_index()\n\n# convert visit type to indicator\nfor c in visit_type_dummies.columns:\n    patient_summary[c] = (patient_summary[c] > 0).astype(int)\n\n\n# ------------------ CELL ------------------\n\ndf = df.merge(patient_summary, on='patient_id', how='left')\n\n# -----------------------------\n# \u2705 FIX: fill NaNs with 0\n# -----------------------------\nfill_cols = [c for c in patient_summary.columns if c != 'patient_id']\ndf[fill_cols] = df[fill_cols].fillna(0).astype(int)\n\n\n# ------------------ CELL ------------------\n\ndf.head()\n\n# ------------------ CELL ------------------\n\n# --- ensure date columns are datetime ---\nvisit = visit.copy()\nfor col in ['visit_end_dt', 'follow_up_dt']:\n    if col in visit.columns:\n        visit[col] = pd.to_datetime(visit[col], errors='coerce')\n\n# --- 1) one-hot / binary columns for visit_type (similar to diagnosis pivot) ---\nunique_visit_types = visit['visit_type'].dropna().unique()\n\nvisit_type_binary = visit[['patient_id', 'visit_type']].copy()\nvisit_type_binary['has_visit_type'] = 1\n\nvisit_type_pivot = visit_type_binary.pivot_table(\n    index='patient_id',\n    columns='visit_type',\n    values='has_visit_type',\n    fill_value=0\n).reset_index()\n\n# If any visit_type column names collide with df, you can keep as-is or rename:\nvisit_type_cols = [c for c in visit_type_pivot.columns if c != 'patient_id']\n# optional: add prefix\nvisit_type_pivot = visit_type_pivot.rename(columns={c: f\"visit_type__{c}\" for c in visit_type_cols})\nvisit_type_cols = [f\"visit_type__{c}\" for c in visit_type_cols]\n\n# --- 2) total visits per patient ---\nvisits_count = visit.groupby('patient_id').size().reset_index(name='total_visits')\n\n# --- 3) min / max difference in days between follow_up_dt and visit_end_dt per patient ---\nif {'visit_end_dt', 'follow_up_dt'}.issubset(visit.columns):\n    visit['diff_days'] = (visit['follow_up_dt'] - visit['visit_end_dt']).dt.days\nelse:\n    visit['diff_days'] = pd.NA\n\ndiff_stats = visit.groupby('patient_id').agg(\n    min_diff_days=('diff_days', 'min'),\n    max_diff_days=('diff_days', 'max'),\n    mean_diff_days=('diff_days', 'mean')  # optional\n).reset_index()\n\n# --- Merge everything into df ---\ndf = df.merge(visit_type_pivot, on='patient_id', how='left')\ndf = df.merge(visits_count, on='patient_id', how='left')\ndf = df.merge(diff_stats, on='patient_id', how='left')\n\n# --- Fill NaNs ---\nfor col in visit_type_cols:\n    df[col] = df[col].fillna(0)\n\ndf['total_visits'] = df['total_visits'].fillna(0).astype(int)\n\n# --- 4) visit_type_ratio: proportion of unique visit types patient has ---\nnum_visit_types = len(unique_visit_types) if len(unique_visit_types) > 0 else 1\ndf['visit_type_ratio'] = df[visit_type_cols].sum(axis=1) / num_visit_types\n\n# --- final: show head ---\n\n\n# ------------------ CELL ------------------\n\ndf.info()\n\n# ------------------ CELL ------------------\n\n# --- Count readmission 't' and 'f' per patient ---\nreadmission_stats = (\n    visit.groupby(['patient_id', 'readmsn_ind'])\n    .size()\n    .unstack(fill_value=0)  # creates columns 'f' and 't'\n    .reset_index()\n)\n\n# Ensure both columns exist (some patients may have only 't' or only 'f')\nfor col in ['t', 'f']:\n    if col not in readmission_stats.columns:\n        readmission_stats[col] = 0\n\n# --- Merge only counts into df ---\ndf = df.merge(\n    readmission_stats[['patient_id', 't', 'f']],\n    on='patient_id',\n    how='left'\n)\n\n# Rename columns for clarity\ndf = df.rename(columns={\n    't': 'readmission_true_count',\n    'f': 'readmission_false_count'\n})\n\n# Fill missing values with 0\ndf[['readmission_true_count', 'readmission_false_count']] = (\n    df[['readmission_true_count', 'readmission_false_count']].fillna(0)\n)\n\n# --- Display updated DataFrame ---\n\n\n# ------------------ CELL ------------------\n\n# --- Count total follow_up_date entries per patient ---\nfollow_up_counts = (\n    visit.groupby('patient_id')['follow_up_dt']\n    .count()  # counts non-null follow_up_date values\n    .reset_index(name='total_followups')\n)\n\n# --- Merge this count into df --\ndf = df.merge(\n    follow_up_counts,\n    on='patient_id',\n    how='left'\n)\n\n# --- Fill missing values with 0 (for patients with no follow-ups) ---\ndf['total_followups'] = df['total_followups'].fillna(0).astype(int)\n\n# --- Display updated DataFrame ---\n\n\n# ------------------ CELL ------------------\n\ndf['follow_up_ratio'] = df['total_followups']/df['total_visits']\n\n# ------------------ CELL ------------------\n\ndf.columns\n\n# ------------------ CELL ------------------\n\ndf\n\n# ------------------ CELL ------------------\n\n# Check for null values in each column and display columns with NaNs\nnan_columns = df.columns[df.isnull().any()].tolist()\nprint(\"Columns with NaN values:\")\nprint(nan_columns)\n\n# ------------------ CELL ------------------\n\n# Identify the one-hot encoded visit type columns\nvisit_type_cols = [col for col in df.columns if col.startswith('visit_type__')]\n\n# Calculate the weighted visits for each visit type\nfor col in visit_type_cols:\n    df[f'{col}_weighted'] = df[col] * df['total_visits']\n\n# Create a single column with the sum of weighted visits for each patient\nweighted_visit_cols = [f'{col}_weighted' for col in visit_type_cols]\ndf['weighted_visits'] = df[weighted_visit_cols].sum(axis=1)\n\n# Display the updated DataFrame with the new weighted columns and the total weighted_visits\n\n# ------------------ CELL ------------------\n\ndef handle_missing_values(df):\n    \"\"\"\n    Intelligently handle missing values based on feature type and medical context\n    \"\"\"\n    # Create flags for missing data (often meaningful in medical context)\n    df['has_care_data'] = df['msrmnt_type_subtype'].notna().astype(int)\n    df['has_care_gap_data'] = df['care_gap_ind'].notna().astype(int)\n\n    # For numerical features, use median instead of 0\n    numerical_cols = ['min_diff_days', 'max_diff_days', 'mean_diff_days',\n                      'time_since_hotspot_identified', 'weighted_visits']\n    for col in numerical_cols:\n        if col in df.columns:\n            median_val = df[col].median()\n            df[col] = df[col].fillna(median_val)\n            print(f\"  \u2713 Filled {col} with median: {median_val:.2f}\")\n\n    # For follow_up_ratio, 0 is meaningful (no follow-up)\n    if 'follow_up_ratio' in df.columns:\n        df['follow_up_ratio'] = df['follow_up_ratio'].fillna(0)\n        print(f\"  \u2713 Filled follow_up_ratio with 0\")\n\n    # Categorical - keep as is but add meaningful label\n    if 'msrmnt_type_subtype' in df.columns:\n        df['msrmnt_type_subtype'] = df['msrmnt_type_subtype'].fillna('no_screening')\n\n    if 'care_gap_ind' in df.columns:\n        df['care_gap_ind'] = df['care_gap_ind'].fillna('no_data')\n\n    print(\"\u2713 Missing values handled\")\n    return df\n\ndef create_medical_features(df):\n    \"\"\"\n    Create clinically meaningful features based on medical knowledge\n    \"\"\"\n    print(\"Creating medical features...\")\n\n    # 1. Comorbidity score (weighted by severity)\n    if all(col in df.columns for col in ['DIABETES', 'HYPERTENSION', 'CANCER']):\n        df['comorbidity_score'] = (\n            df['DIABETES'] * 1 +      # Moderate severity\n            df['HYPERTENSION'] * 1 +  # Moderate severity\n            df['CANCER'] * 3         # High severity\n        )\n        print(\"  \u2713 Comorbidity score created\")\n\n    # 2. Healthcare utilization intensity\n    if all(col in df.columns for col in ['visit_type_URGENTCARE', 'visit_type_ER', 'visit_type_INPATIENT']):\n        df['utilization_intensity'] = (\n            df['visit_type_URGENTCARE']*2 +\n            df['visit_type__ER'] * 3 +       # ER visits weighted heavily\n            df['visit_type__INPATIENT'] * 5  # Inpatient visits significant\n        )\n        print(\"  \u2713 Utilization intensity created\")\n\n    # 3. Patient engagement score\n    if all(col in df.columns for col in ['total_followups', 'follow_up_ratio']):\n        df['patient_engagement'] = (\n            (df['total_followups'] > 0).astype(int) +\n            (df['follow_up_ratio'] > 0.5).astype(int) +\n            (df['care_gap_ind'] != 'no_data').astype(int)\n        )\n        print(\"  \u2713 Patient engagement score created\")\n\n    # 4. Age risk categories (standard geriatric categories)\n    if 'age' in df.columns:\n        df['age_risk_category'] = pd.cut(\n            df['age'],\n            bins=[0, 18, 45, 65, 100],\n            labels=['pediatric', 'adult', 'senior', 'geriatric']\n        )\n        # Convert to dummy variables\n        age_dummies = pd.get_dummies(df['age_risk_category'], prefix='age_cat')\n        df = pd.concat([df, age_dummies], axis=1)\n        df = df.drop('age_risk_category', axis=1)\n        print(\"  \u2713 Age risk categories created\")\n\n    # 5. Acute vs Chronic care ratio\n    if all(col in df.columns for col in ['total_vist_actue', 'chronic_ratio']):\n        df['acute_chronic_ratio'] = df['total_vist_actue'] / (df['chronic_ratio'] + 0.01)\n        print(\"  \u2713 Acute/chronic ratio created\")\n\n    # 6. Care continuity (inverse of days between visits)\n    if 'mean_diff_days' in df.columns:\n        df['care_continuity_score'] = np.where(\n            df['mean_diff_days'] > 0,\n            1 / (df['mean_diff_days'] + 1),\n            0\n        )\n        print(\"  \u2713 Care continuity score created\")\n\n    # 7. High-risk flags\n    if 'age' in df.columns:\n        df['is_high_risk_age'] = (df['age'] >= 65).astype(int)\n        print(\"  \u2713 High-risk age flag created\")\n\n    if 'comorbidity_score' in df.columns:\n        df['is_high_comorbidity'] = (df['comorbidity_score'] >= 2).astype(int)\n        print(\"  \u2713 High comorbidity flag created\")\n\n    print(\"\u2713 All medical features created\")\n    return df\n\n\ndef stratify_risk(predictions, percentiles=[50, 75, 90]):\n    \"\"\"\n    Categorize patients into actionable risk tiers\n    \"\"\"\n    thresholds = np.percentile(predictions, percentiles)\n\n    def assign_risk(score):\n        if score < thresholds[0]:\n            return 'Low Risk'\n        elif score < thresholds[1]:\n            return 'Moderate Risk'\n        elif score < thresholds[2]:\n            return 'High Risk'\n        else:\n            return 'Critical Risk'\n\n    return np.array([assign_risk(s) for s in predictions])\n\nprint(\"\u2713 Utility functions defined\")\n\n\n# ------------------ CELL ------------------\n\ndf = handle_missing_values(df)\ndf = create_medical_features(df)\n\n\n\n# ------------------ CELL ------------------\n\n\n\n# ------------------ CELL ------------------\n\n# Drop rows with any NaN values\ndf = df.dropna(axis=1)\n\n# Check for null values in each column after dropping NaNs and display columns with NaNs\nnan_columns = df.columns[df.isnull().any()].tolist()\nprint(\"Columns with NaN values after dropping rows:\")\nprint(nan_columns)\n\n# Display the updated DataFrame head\n\n# ------------------ CELL ------------------\n\n#import pandas as pd\n#Merge data and risk on patient_id\n#data = pd.merge(df, risk, on='patient_id', how='left')\n\n# Display the updated data DataFrame\n#display(data.head())\n\ndata = df.copy()\n\n# ------------------ CELL ------------------\n\n\n\n# ------------------ CELL ------------------\n\ncols_to_keep = [\n    'age', 'comorbidity_score', 'chronic_ratio', 'HYPERTENSION',\n    'age_cat_senior', 'is_high_comorbidity', 'DIABETES', 'patient_engagement',\n    'visit_type_ER_weighted', 'is_high_risk_age', 'visit_type_ER', 'visit_type_ER_',\n    'msrmnt_type_subtype_SCREENING_COLORECTAL_CANCER', 'weighted_visits',\n    'visit_type_ratio', 'visit_diag_ratio', 'total_visits', 'visit_count',\n    'total_readmissions', 'age_cat_geriatric', 'total_followups', 'follow_up_ratio',\n    'visit_type_INPATIENT_weighted', 'visit_type_INPATIENT', 'CANCER', 'diag_Other',\n    'hot_spotter_chronic_flag_t', 'diag_Neurology/Psych',\n    'msrmnt_type_subtype_SCREENING_COLORECTAL_CANCER_SCREENING_BREAST_CANCER',\n    'diag_Cardiovascular', 'diag_GI',\n    'msrmnt_type_subtype_SCREENING_BREAST_CANCER_SCREENING_COLORECTAL_CANCER',\n    'diag_Skin/Soft Tissue', 'hot_spotter_chronic_flag_f', 'age_cat_adult',\n    'msrmnt_type_subtype_no_screening', 'age_cat_pediatric'\n]\n\n\n# ------------------ CELL ------------------\n\nlen(cols_to_keep)\n\n# ------------------ CELL ------------------\n\ndata = data[[c for c in cols_to_keep if c in data.columns]]\n\n\n# ------------------ CELL ------------------\n\ndata.info()\n\n# ------------------ CELL ------------------\n\nmissing_cols = [c for c in cols_to_keep if c not in data.columns]\nmissing_cols\n\n\n# ------------------ CELL ------------------\n\n\n\n# ------------------ CELL ------------------\n\ndata.head()\n\n# ------------------ CELL ------------------\n\ndata.shape\n\n# ------------------ CELL ------------------\n\nimport pickle\n\n# ------------------ CELL ------------------\n\nimport pickle\n")
        
        try:
            # execute the preprocessing script; it should produce a DataFrame named 'data' (as in the notebook)
            ns = runpy.run_path(preproc_path)
        except Exception as e:
            st.error(f'Error while running preprocessing: {e}')
            raise
        
        # Attempt to locate the processed DataFrame and cols_to_keep
        if 'data' in ns:
            data = ns['data']
        elif 'df' in ns:
            data = ns['df']
        else:
            st.error('Preprocessing did not produce a DataFrame named "data" or "df". Check the notebook code.')
            st.stop()

        cols = ns.get('cols_to_keep', None)
        st.success('Preprocessing completed.')
        st.write('Processed data preview:')
        st.dataframe(data.head())

        # Load model
        if not os.path.exists('model_up.pkl'):
            st.error('model_up.pkl not found in repo root. Please upload it to the repo or place it in the working directory.')
            st.stop()

        with open('model_up.pkl','rb') as f:
            model = pickle.load(f)

        # Determine features to use
        if cols:
            features = data[cols]
        else:
            # try to infer by intersection
            possible_cols = [c for c in data.columns if c in model.feature_names_in_ if hasattr(model, 'feature_names_in_') ]
            if possible_cols:
                features = data[possible_cols]
            else:
                # fallback to using all numeric columns
                features = data.select_dtypes(include=[np.number])

        # predict
        try:
            preds = model.predict(features)
        except Exception as e:
            st.error(f'Prediction error: {e}')
            st.stop()

        # assemble results
        if 'patient_id' in data.columns:
            out = pd.DataFrame({'patient_id': data['patient_id'], 'predicted_risk_score': preds})
        else:
            out = pd.DataFrame(preds, columns=['predicted_risk_score'])
        st.write('Predictions:')
        st.dataframe(out.head(200))

        # download
        csv = out.to_csv(index=False).encode('utf-8')
        st.download_button('Download predictions CSV', data=csv, file_name='predictions.csv', mime='text/csv')

st.markdown('---')
st.info('If preprocessing fails, paste the preprocessing code block from your notebook into the repo as cleaned_preprocessing.py or into the notebook and try again.')

# EOF
